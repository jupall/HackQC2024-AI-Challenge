{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plant.id API\n",
    "\n",
    "let's run some quick tests!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kindwise import PlantApi\n",
    "my_api_key = \"...\"\n",
    "api = PlantApi(my_api_key)\n",
    "\n",
    "identification = api.identify('my_hidden_photo_3.jpg', details=['url', 'common_names'])\n",
    "\n",
    "print('is plant' if identification.result.is_plant.binary else 'is not plant')\n",
    "for suggestion in identification.result.classification.suggestions:\n",
    "    print(suggestion.name)\n",
    "    print(f'probability {suggestion.probability:.2%}')\n",
    "    print(suggestion.details['url'], suggestion.details['common_names'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustimage\n",
    "\n",
    "For the ai challenge, let's try this library.\n",
    "\n",
    "Todos:\n",
    "- find a way to crop images to only select the pole\n",
    "- unsupervised image clustering, find a good combination of hyperparameters and a method (pca or Hog ?)\n",
    "- for each image, use their cluster number as a feature and add weather data.\n",
    "- using this, do another unsupervised clustering with the data.\n",
    "- manually label each of these cluster and make sure that they have sense.\n",
    "- Then, when you get a new image, predict it's closest cluster in image, and use it for the prediction of the second clustering.\n",
    "- Finally, use the manual label to identify the situation?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## crop images around object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/.local/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\u001b[0m\n",
      "  warnings.warn(problem)\n"
     ]
    }
   ],
   "source": [
    "from rembg import remove\n",
    "\n",
    "input_path = 'input.png'\n",
    "output_path = 'output.png'\n",
    "\n",
    "with open(input_path, 'rb') as i:\n",
    "    with open(output_path, 'wb') as o:\n",
    "        input = i.read()\n",
    "        output = remove(input)\n",
    "        o.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rembg import remove\n",
    "from PIL import Image\n",
    "\n",
    "input_path = 'image.png'\n",
    "output_path = 'output.png'\n",
    "\n",
    "input = Image.open(input_path)\n",
    "output = remove(input)\n",
    "output.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/julien/.local/lib/python3.10/site-packages/cv2/qt/plugins\"\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "my_sample_image = \"./input.png\"\n",
    "#reading image\n",
    "image = cv2.imread(my_sample_image)\n",
    "  \n",
    "# Window name in which image is displayed \n",
    "window_name = 'fenetre'\n",
    "  \n",
    "# Using cv2.imshow() method \n",
    "# Displaying the image \n",
    "cv2.imshow(window_name, image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to gray scale\n",
    "gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(window_name, gray)\n",
    "#cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#applying canny edge detection\n",
    "edged = cv2.Canny(gray, 50, 600)\n",
    "cv2.imshow(window_name, edged)\n",
    "#cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copyedge = edged.copy()\n",
    "contours, hierarchy = cv2.findContours(copyedge, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.drawContours(copyedge, contours, -1, (100,100,100), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(window_name, copyedge)\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "idx = 0\n",
    "for c in contours:\n",
    "\tx,y,w,h = cv2.boundingRect(c)\n",
    "\tif w>50 and h>50:\n",
    "\t\tidx+=1\n",
    "\t\tnew_img=image[y:y+h,x:x+w]\n",
    "\t\t#cropping images\n",
    "\t\tcv2.imwrite(\"./cropped/\"+str(idx) + '.png', new_img)\n",
    "#cv2.imshow(\"Original Image\",image)\n",
    "#cv2.imshow(\"Canny Edge\",edged)\n",
    "#cv2.waitKey(0)\n",
    "print('>> Objects Cropped Successfully!')\n",
    "print(\">> Check out 'cropped' Directory\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, w, h = 100, 100, 300, 300\n",
    "region_of_interest = image[y:y+h, x:x+w]\n",
    "cv2.imshow(region_of_interest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You only look once\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromDarknet('./yolov3.cfg', 'yolov3.weights')\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = net.getLayerNames()\n",
    "net.setInput(blob)\n",
    "t0 = time.time()\n",
    "outputs = net.forward(ln)\n",
    "t = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "from clustimage import Clustimage\n",
    "\n",
    "# Initialize with HOG\n",
    "#cl = Clustimage(method='hog', params_hog={'orientations':20, 'pixels_per_cell':(16,16), 'cells_per_block':(2,2)})\n",
    "\n",
    "# Initialize with pca and 50 PCs\n",
    "#cl = Clustimage(method='pca', params_pca={'n_components':50})\n",
    "# Take the number of components that covers 95% of the data\n",
    "#cl = Clustimage(method='pca',dim=(256, 256), params_pca={'n_components':0.98})\n",
    "cl = Clustimage(method='pca',dim=(128, 128), params_hog={'orientations':20, 'pixels_per_cell':(8,8), 'cells_per_block':(1,1)}, params_pca={'n_components':0.6})\n",
    "\n",
    "\n",
    "# load example with flowers\n",
    "pathnames = cl.import_example(data='flowers')\n",
    "\n",
    "# The pathnames are stored in a list\n",
    "print(pathnames[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = \"../../SygivreComplet/ABITIBI/\"\n",
    "\n",
    "\n",
    "#results = cl.fit_transform('C://101_ObjectCategories//', min_clust=30, max_clust=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocessing, feature extraction and clustering.\n",
    "results = cl.fit_transform(mypath, min_clust=4, max_clust=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl.clusteval.plot()\n",
    "cl.clusteval.scatter(cl.results['xycoord'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot unique images\n",
    "cl.plot_unique()\n",
    "cl.plot_unique(img_mean=False)\n",
    "\n",
    "# Plot all images per cluster\n",
    "cl.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter\n",
    "cl.scatter(dotsize=50, zoom=None)\n",
    "cl.scatter(dotsize=50, zoom=0.5)\n",
    "cl.scatter(dotsize=50, zoom=0.5, img_mean=False)\n",
    "cl.scatter(dotsize=50, zoom=0.5, img_mean=False)\n",
    "cl.scatter(zoom=1.2, plt_all=True, figsize=(150,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment Anything and opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## self-supervised "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLava"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
